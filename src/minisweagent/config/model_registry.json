{
    "gpt-5": {
        "max_tokens": 128000,
        "max_input_tokens": 400000,
        "max_output_tokens": 128000,
        "input_cost_per_token": 1.25e-06,
        "output_cost_per_token": 1e-05,
        "cache_read_input_token_cost": 1.25e-07,
        "litellm_provider": "openai",
        "mode": "chat",
        "supported_endpoints": [
            "/v1/chat/completions",
            "/v1/batch",
            "/v1/responses"
        ],
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_pdf_input": true,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_response_schema": true,
        "supports_vision": true,
        "supports_prompt_caching": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_native_streaming": true,
        "supports_reasoning": true
    },
    "gpt-5-mini": {
        "max_tokens": 128000,
        "max_input_tokens": 400000,
        "max_output_tokens": 128000,
        "input_cost_per_token": 2.5e-07,
        "output_cost_per_token": 2e-06,
        "cache_read_input_token_cost": 2.5e-08,
        "litellm_provider": "openai",
        "mode": "chat",
        "supported_endpoints": [
            "/v1/chat/completions",
            "/v1/batch",
            "/v1/responses"
        ],
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_pdf_input": true,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_response_schema": true,
        "supports_vision": true,
        "supports_prompt_caching": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_native_streaming": true,
        "supports_reasoning": true
    }
}